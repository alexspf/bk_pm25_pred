{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bakersfield PM2.5 Prediction\n",
    " This notebook focuses on obtaining the best subset of the database for Bakersfield city in California to train a model for predicting PM2.5 concentration in the air.<br>\n",
    " \n",
    "<img src=\"images/reference.png\" alt=\"\" style=\"width:450px;\"> \n",
    "<img src=\"images/city.png\" alt=\"\" style=\"width:450px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dfs = {}\n",
    "\n",
    "for i in range(1999, 2025):\n",
    "    dfs[f\"df{i-1998}\"] = pd.read_csv(f\"data_raw/pm25_{i}.csv\")\n",
    "\n",
    "data = pd.concat(dfs.values(), ignore_index=True, verify_integrity=True)\n",
    "\n",
    "data.to_csv('data_mod/data_merge.csv', index=False) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the data in Bakersfield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all((data['CBSA_NAME'].unique())=='Bakersfield, CA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Bakersfield sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equal = data['Site Name'].nunique() == data['Site ID'].nunique()\n",
    "\n",
    "if equal:\n",
    "    print(\"IDs=Sites Names.\")\n",
    "else:\n",
    "    print(\"IDs!=Sites Names.\")\n",
    "\n",
    "\n",
    "for i, (site_id, group) in enumerate(data.groupby('Site ID'), start=1):\n",
    "    filename = f\"data_mod/id_{i}.csv\"\n",
    "    group.to_csv(filename, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The site with the most data on Bakersfield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows_per_id = []\n",
    "\n",
    "for site_id in range(1, 13):\n",
    "    filename = f\"data_mod/id_{site_id}.csv\"\n",
    "    df = pd.read_csv(filename)\n",
    "    \n",
    "    num_rows = len(df)\n",
    "    num_rows_per_id.append(num_rows)\n",
    "\n",
    "    print(f\"The DataFrame for 'Site ID' {site_id} has {num_rows} rows.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check duplitcates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame original shape: (23321, 20)\n",
      "data unique shape: (23321, 20)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the DataFrame from the CSV file\n",
    "data = pd.read_csv(\"data_mod/id_3.csv\")\n",
    "data['Date'] = pd.to_datetime(data['Date'], format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "data_original = data.copy()\n",
    "\n",
    "data_unique = data.drop_duplicates()\n",
    "\n",
    "print(f'DataFrame original shape: {data_original.shape}')\n",
    "print(f'data unique shape: {data_unique.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's start!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
